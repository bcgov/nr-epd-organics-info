# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
#-- global variables, can be accessed by sub-charts.
global:
  #-- the registry where the images are stored. override during runtime for other registry at global level or individual level.
  repository: ~ # provide the repo name from where images will be sourced for example bcgo
  #-- the registry where the images are stored. override during runtime for other registry at global level or individual level. default is ghcr.io
  registry: ghcr.io # ghcr.io for directly streaming from github container registry or "artifacts.developer.gov.bc.ca/github-docker-remote" for artifactory, or any other registry.
  #-- the tag of the image, it can be latest, 1.0.0 etc..., or the sha256 hash
  tag: ~
  #-- turn off autoscaling for the entire suite by setting this to false. default is true.
  autoscaling: true
  #-- global secrets, can be accessed by sub-charts.
  secrets:
    enabled: true
    databasePassword: ~
    databaseUser: ~
    databaseName: ~
    annotation:
      helm.sh/policy: "keep"
    osBucket: ~
    osAccessKeyId: ~
    osSecretAccessKeyId: ~
    osEndpoint: ~
  #-- domain of the application, it is required, apps.silver.devops.gov.bc.ca for silver cluster and apps.devops.gov.bc.ca for gold cluster
  domain: "apps.silver.devops.gov.bc.ca" # it is apps.gold.devops.gov.bc.ca for gold cluster
  #-- the database Alias gives a nice way to switch to different databases, crunchy, patroni ... etc.
  databaseAlias: bitnami-pg
#-- the components of the application, backend.
backend:
  #-- enable or disable backend
  enabled: true
  #-- the deployment strategy, can be "Recreate" or "RollingUpdate"
  deploymentStrategy: Recreate
  imagePullPolicy: Always
  #-- autoscaling for the component. it is optional and is an object.
  initContainerResources:
    limits:
      cpu: 100m
      memory: 200Mi
    requests:
      cpu: 30m
      memory: 100Mi
  containerResources:
    limits:
      cpu: 100m
      memory: 200Mi
    requests:
      cpu: 30m
      memory: 100Mi
  autoscaling:
    #-- enable or disable autoscaling.
    enabled: true
    #-- the minimum number of replicas.
    minReplicas: 3
    #-- the maximum number of replicas.
    maxReplicas: 7
    #-- the target cpu utilization percentage, is from request cpu and NOT LIMIT CPU.
    targetCPUUtilizationPercentage: 80
  #-- the service for the component. for inter namespace communication, use the service name as the hostname.
  service:
    #-- the type of the service. it can be ClusterIP, NodePort, LoadBalancer, ExternalName. ClusterIP is the default and is recommended.
    type: ClusterIP
    port: 80 # this is the service port, where it will be exposed internal to the namespace.
    targetPort: 3000 # this is container port where app listens on
  pdb:
    enabled: false # enable it in PRODUCTION for having pod disruption budget.
    minAvailable: 1 # the minimum number of pods that must be available during the disruption budget.

frontend:
  # -- enable or disable a component deployment.
  enabled: true
  # -- the deployment strategy, can be "Recreate" or "RollingUpdate"
  deploymentStrategy: Recreate
  imagePullPolicy: Always
  containerResources:
    limits:
      cpu: 60m
      memory: 100Mi
    requests:
      cpu: 20m
      memory: 30Mi
  #-- autoscaling for the component. it is optional and is an object.
  autoscaling:
    #-- enable or disable autoscaling.
    enabled: true
    #-- the minimum number of replicas.
    minReplicas: 3
    #-- the maximum number of replicas.
    maxReplicas: 7
    #-- the target cpu utilization percentage, is from request cpu and NOT LIMIT CPU.
    targetCPUUtilizationPercentage: 80
  #-- the service for the component. for inter namespace communication, use the service name as the hostname.
  service:
    type: ClusterIP
  #-- the route for the component. it is optional and is an object. To make the application accessible from internet, use the route.
  pdb:
    enabled: false # enable it in PRODUCTION for having pod disruption budget.
    minAvailable: 1 # the minimum number of pods that must be available during the disruption budget.

crunchy: # enable it for TEST and PROD, for PR based pipelines simply use single postgres
  enabled: false

  crunchyImage: artifacts.developer.gov.bc.ca/bcgov-docker-local/crunchy-postgres-gis:ubi8-15.2-3.3-0

  postgresVersion: 15
  postGISVersion: '3.3'
  imagePullPolicy: Always
  instances:
    name: ha # high availability
    replicas: 1 # 2 or 3 for high availability in TEST and PROD.
    metadata:
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9187'
    dataVolumeClaimSpec:
      storage: 120Mi
      storageClassName: netapp-block-standard
    requests:
      cpu: 25m
      memory: 256Mi
    limits:
      cpu: 100m
      memory: 512Mi
    replicaCertCopy:
      requests:
        cpu: 1m
        memory: 32Mi
      limits:
        cpu: 50m
        memory: 64Mi

  pgBackRest:
    enabled: false
    image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
    retention: "1" # Ideally a larger number such as 30 backups/days
    # If retention-full-type set to 'count' then the oldest backups will expire when the number of backups reach the number defined in retention
    # If retention-full-type set to 'time' then the number defined in retention will take that many days worth of full backups before expiration
    retentionFullType: count
    repos:
      schedules:
        full: 0 8 * * *
        incremental: 0 0,4,12,16,20 * * *
      volume:
        accessModes: "ReadWriteOnce"
        storage: 64Mi
        storageClassName: netapp-file-backup
    repoHost:
      requests:
        cpu: 1m
        memory: 64Mi
      limits:
        cpu: 50m
        memory: 128Mi
    sidecars:
      requests:
        cpu: 1m
        memory: 64Mi
      limits:
        cpu: 50m
        memory: 128Mi

  patroni:
    postgresql:
      pg_hba: "host all all 0.0.0.0/0 md5"
      parameters:
        shared_buffers: 16MB # default is 128MB; a good tuned default for shared_buffers is 25% of the memory allocated to the pod
        wal_buffers: "64kB" # this can be set to -1 to automatically set as 1/32 of shared_buffers or 64kB, whichever is larger
        min_wal_size: 32MB
        max_wal_size: 64MB # default is 1GB
        max_slot_wal_keep_size: 128MB # default is -1, allowing unlimited wal growth when replicas fall behind

  proxy:
    pgBouncer:
      image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
      replicas: 1
      requests:
        cpu: 1m
        memory: 64Mi
      limits:
        cpu: 50m
        memory: 128Mi

  # Postgres Cluster resource values:
  pgmonitor:
    enabled: false
    exporter:
      image: # it's not necessary to specify an image as the images specified in the Crunchy Postgres Operator will be pulled by default
      requests:
        cpu: 1m
        memory: 64Mi
      limits:
        cpu: 50m
        memory: 128Mi

bitnami-pg:
  enabled: false
  image:
    registry: ghcr.io
    repository: bcgov/nr-containers/bitnami/postgresql
    tag: 15.6.0
  auth:
    existingSecret: '{{ .Release.Name }}'
    username: omrr
    database: omrr
  shmVolume:
    enabled: false
  backup:
    enabled: false
    cronjob:
      containerSecurityContext: { }
      podSecurityContext:
        enabled: false
      storage:
        size: 200Mi
  primary:
    persistence:
      enabled: true
      storageClass: netapp-block-standard
      accessModes:
        - ReadWriteOnce
      size: 100Mi
    containerSecurityContext:
      enabled: false
    podSecurityContext:
      enabled: false
    initdb:
      scripts: # remove the below script, if POSTGIS is not required.
        postgis.sh: |
          #!/bin/sh
          PGPASSWORD=$POSTGRES_PASSWORD psql -U postgres -d postgres -c "CREATE EXTENSION postgis;"
    resources:
      requests:
        cpu: 30m
        memory: 100Mi
      limits:
        cpu: 90m
        memory: 250Mi
